{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from coffea import util, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the output files produced from running the full analysis on condor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputMC = util.load(f'Outputs/outputMCOther_ttgamma_condorFull_4jet.coffea')\n",
    "outputMC.add(util.load(f'Outputs/outputMCSingletop_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTbar1l_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTbar2l_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTGamma_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCWJets_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCZJets_ttgamma_condorFull_4jet.coffea'))\n",
    "\n",
    "outputData = util.load(f'Outputs/outputData_ttgamma_condorFull_4jet.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping= {'ttgamma': ['TTGamma_Dilepton','TTGamma_SingleLept','TTGamma_Hadronic'],\n",
    "           'ttbar'  : ['TTbarPowheg_Dilepton', 'TTbarPowheg_Semilept', 'TTbarPowheg_Hadronic'],\n",
    "           'Single top':['ST_s_channel', 'ST_tW_channel', 'ST_tbarW_channel', 'ST_tbar_channel', 'ST_t_channel'],\n",
    "           'Wgamma' : ['WGamma_01J_5f'],\n",
    "           'Zgamma' : ['ZGamma_01J_5f_lowMass'],\n",
    "           'Other'    : ['TTWtoLNu','TTWtoQQ','TTZtoLL','W1jets', 'W2jets', 'W3jets', 'W4jets','DYjetsM10to50', 'DYjetsM50','GJets_HT40To100', 'GJets_HT100To200', 'GJets_HT200To400', 'GJets_HT400To600', 'GJets_HT600ToInf', 'QCD_Pt20to30_Ele', 'QCD_Pt30to50_Ele', 'QCD_Pt50to80_Ele', 'QCD_Pt80to120_Ele', 'QCD_Pt120to170_Ele', 'QCD_Pt170to300_Ele', 'QCD_Pt300toInf_Ele', 'QCD_Pt20to30_Mu', 'QCD_Pt30to50_Mu', 'QCD_Pt50to80_Mu', 'QCD_Pt80to120_Mu', 'QCD_Pt120to170_Mu', 'QCD_Pt170to300_Mu', 'QCD_Pt300to470_Mu', 'QCD_Pt470to600_Mu', 'QCD_Pt600to800_Mu', 'QCD_Pt800to1000_Mu', 'QCD_Pt1000toInf_Mu']\n",
    "          }\n",
    "\n",
    "groupingPho= {\"Genuine\":slice(1,2),\n",
    "              \"MisIDele\": slice(2,3),\n",
    "              \"NonPrompt\":slice(3,5),\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load histograms from MC and Data, to extract the number of events split by photon category and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = outputMC['M3'].sum('lepFlavor').sum('M3').group('dataset',hist.Cat(r'dataset',r'Samples',sorting='placement'),grouping)\n",
    "h = h.group('category',hist.Cat(r'category',r'Category',sorting='placement'),groupingPho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hData = outputData['M3'].sum('lepFlavor').sum('M3').sum('dataset').sum('category')\n",
    "nData = hData.values()[('noweight',)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = h.integrate('systematic','nominal').values()\n",
    "mcYield = []\n",
    "\n",
    "for i, sample in enumerate(grouping.keys()):\n",
    "    mcYield.append([])\n",
    "    for j, category in enumerate(groupingPho.keys()):\n",
    "        v = vals[(category,sample)]\n",
    "        mcYield[-1].append(v)\n",
    "mcYield = np.array(mcYield)\n",
    "\n",
    "errs = h.integrate('systematic','nominal')._sumw2\n",
    "\n",
    "mcYieldErr = []\n",
    "for s in errs:\n",
    "    mcYieldErr.append(errs[s]**0.5)\n",
    "\n",
    "mcYieldErr = np.array(mcYieldErr)\n",
    "mcYieldErr.shape = (3,6)\n",
    "mcYieldErr = mcYieldErr.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in dictionaries of the results of the misidentified electron scale factor, photon purity, and top purity fits for the nominal and all systematic uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MisIDSFResults = {'nominal': 1.,\n",
    "                 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photonPurityResults = {'nominal': (0.5, 0.1),\n",
    "\n",
    "                      }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topPurityResults = {'nominal': (0.75, 0.1),\n",
    "                   }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodFunction(ttgammaSF=1., nonPromptSF=1., mcValues=None, mcValuesErr=None, photonPurity=None, topPurity=None, nData = None, photonPurityErr=None, topPurityErr=None):\n",
    "    mcValues[0] *= ttgammaSF\n",
    "    mcValuesErr[0] *= ttgammaSF\n",
    "\n",
    "    mcValues[:,-1] *= nonPromptSF\n",
    "    mcValuesErr[:,-1] *= nonPromptSF\n",
    "    \n",
    "    nMC = mcValues.sum()\n",
    "    nMCErr = (mcValuesErr**2).sum()**0.5\n",
    "\n",
    "    #nIso is the sum of the first two columsn of data (genuine and misID)\n",
    "    nIso = mcValues[:,0:2].sum()\n",
    "    nIsoErr = (mcValuesErr[:,0:2]**2).sum()**0.5\n",
    "\n",
    "    #nTop is the sum of the first two rows (ttgamma and ttbar)\n",
    "    nTop = mcValues[0:2].sum()\n",
    "    nTopErr = (mcValuesErr[0:2]**2).sum()**0.5\n",
    "\n",
    "    mcPhotonPurity    = nIso/nMC\n",
    "    mcPhotonPurityErr = (mcPhotonPurity) * ((nIsoErr/nIso)**2 + (nMCErr/nMC)**2)**0.5\n",
    "\n",
    "    mcTopPurity = nTop/nMC\n",
    "    mcTopPurityErr = mcTopPurity * ((nTopErr/nTop)**2 + (nMCErr/nMC)**2)**0.5\n",
    "    \n",
    "    \n",
    "    chi2 = ((photonPurity-mcPhotonPurity)**2/(photonPurityErr**2 + mcPhotonPurityErr**2) + \n",
    "            (topPurity - mcTopPurity)**2/(topPurityErr**2 + mcTopPurityErr**2) +\n",
    "            (nData - nMC)**2/(nData + nMCErr**2)\n",
    "           )\n",
    "    \n",
    "    return np.exp(-0.5*chi2)\n",
    "                \n",
    "    \n",
    "\n",
    "def maximizeLikelihood(fitData, \n",
    "                       ttgSF = None, nonPromptSF=None, \n",
    "                       startTTGamma = 1., startNonprompt = 1., \n",
    "                       nSteps = 100,\n",
    "                       verbose=False, \n",
    "                       find1sigma = False, \n",
    "                       nStepsErr = 20):\n",
    "\n",
    "\n",
    "    mcYield=fitData['mcYield']\n",
    "    mcYieldErr=fitData['mcYieldErr']\n",
    "    photonPurity=fitData['photonPurity']\n",
    "    photonPurityErr=fitData['photonPurityErr']\n",
    "    topPurity=fitData['topPurity']\n",
    "    topPurityErr=fitData['topPurityErr']\n",
    "    nData=fitData['nData']\n",
    "    \n",
    "    \n",
    "    if ttgSF is None:\n",
    "        ttgSF=startTTGamma\n",
    "        iTTGSteps = range(3)\n",
    "    else:\n",
    "        iTTGSteps = [1]\n",
    "\n",
    "    if nonPromptSF is None:\n",
    "        nonPromptSF=startNonprompt\n",
    "        iNPSteps = range(3)\n",
    "    else:\n",
    "        iNPSteps = [1]\n",
    "        \n",
    "    stepSize = 0.1\n",
    "    \n",
    "    lastStepLk = -1.\n",
    "\n",
    "    for steps in range(nSteps):\n",
    "\n",
    "        best_lk = -1\n",
    "        best_iTTG = -1\n",
    "        best_iNP = -1\n",
    "        \n",
    "        for iTTG in iTTGSteps:\n",
    "            for iNP in iNPSteps:\n",
    "                lk = likelihoodFunction(ttgammaSF = ttgSF + (iTTG-1)*stepSize , \n",
    "                                        nonPromptSF=nonPromptSF + (iNP-1)*stepSize, \n",
    "                                        mcValues=mcYield.copy(), mcValuesErr=mcYieldErr.copy(),\n",
    "                                        photonPurity=photonPurity, topPurity=topPurity, \n",
    "                                        photonPurityErr=photonPurityErr, topPurityErr=topPurityErr, \n",
    "                                        nData=nData)\n",
    "\n",
    "                if lk > best_lk:\n",
    "                    best_lk = lk\n",
    "                    best_iTTG = iTTG\n",
    "                    best_iNP = iNP\n",
    "\n",
    "        ttgSF = ttgSF+(best_iTTG-1)*stepSize\n",
    "        nonPromptSF = nonPromptSF + (best_iNP-1)*stepSize\n",
    "\n",
    "        if best_iTTG==best_iNP==1:\n",
    "            stepSize = stepSize/2.\n",
    "            lastStepLk=-1.\n",
    "\n",
    "        if verbose:\n",
    "            print(steps, ttgSF, nonPromptSF, stepSize, best_lk)\n",
    "            \n",
    "    if find1sigma:\n",
    "\n",
    "        ### scan for ttgSF down\n",
    "        ttgammaErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = ttgSF - ttgammaErr, \n",
    "                                         nonPromptSF=None, \n",
    "                                         nSteps = 50,\n",
    "                                    )\n",
    "\n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr -= stepSize\n",
    "                trend=-1\n",
    "        ttgammaDown = -1*ttgammaErr\n",
    "\n",
    "        ### scan for ttgSF up\n",
    "        ttgammaErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = ttgSF + ttgammaErr, \n",
    "                                         nonPromptSF=None, \n",
    "                                         nSteps = 50,\n",
    "                                        )\n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr -= stepSize\n",
    "                trend=-1\n",
    "        ttgammaUp = ttgammaErr\n",
    "\n",
    "        ### scan for npSF down\n",
    "        npErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = None, \n",
    "                                         nonPromptSF=nonPromptSF - npErr, \n",
    "                                         nSteps = 50,\n",
    "                                        )            \n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                npErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                npErr -= stepSize\n",
    "                trend=-1\n",
    "        nonPromptDown = -1*npErr\n",
    "\n",
    "        ### scan for npSF up        \n",
    "        npErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = None, \n",
    "                                         nonPromptSF=nonPromptSF + npErr,\n",
    "                                         nSteps = 50,                                         \n",
    "                                        )            \n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                npErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                npErr -= stepSize\n",
    "                trend=-1\n",
    "        nonPromptUp = npErr        \n",
    "        \n",
    "        return ttgSF, ttgammaUp, ttgammaDown, nonPromptSF, nonPromptUp, nonPromptDown, best_lk\n",
    "        \n",
    "    else:\n",
    "        return ttgSF, nonPromptSF, best_lk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run likelihood fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate nominal scale factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misIDEleSF = MisIDSFResults['nominal']\n",
    "\n",
    "mcYield[:,1] *= misIDEleSF\n",
    "mcYieldErr[:,1] *= misIDEleSF\n",
    "\n",
    "\n",
    "fitData = {\n",
    "    'mcYield':mcYield, \n",
    "    'mcYieldErr':mcYieldErr,\n",
    "    'photonPurity':photonPurityResults['nominal'][0], \n",
    "    'photonPurityErr':photonPurityResults['nominal'][1],\n",
    "    'topPurity':topPurityResults['nominal'][0],\n",
    "    'topPurityErr':topPurityResults['nominal'][1], \n",
    "    'nData':nData, \n",
    "}\n",
    "\n",
    "output = maximizeLikelihood(fitData,\n",
    "                        nSteps=100, \n",
    "                        find1sigma=True, \n",
    "                        nStepsErr=100, \n",
    "                        startTTGamma=1,\n",
    "                        startNonprompt=1\n",
    "                       )\n",
    "bestTTGSF, bestTTGSF_Up, bestTTGSF_Down, bestNPSF, bestNPSF_Up, bestNPSF_Down, mxLk = output                                                                                                         \n",
    "print(\"TTGamma SF = %.4f +%.4f %.4f\"%(bestTTGSF, bestTTGSF_Up, bestTTGSF_Down))\n",
    "print(\"nonPrompt SF = %.4f +%.4f %.4f\"%(bestNPSF, bestNPSF_Up, bestNPSF_Down))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run fit for all systematic uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematics = list(photonPurityResults.keys())\n",
    "systematics.remove('nominal')\n",
    "\n",
    "systResults = {}\n",
    "\n",
    "for syst in systematics:\n",
    "    vals = h.integrate('systematic',syst).values()\n",
    "    mcYield = []\n",
    "\n",
    "    for i, sample in enumerate(grouping.keys()):\n",
    "        mcYield.append([])\n",
    "        for j, category in enumerate(groupingPho.keys()):\n",
    "            v = vals[(category,sample)]\n",
    "            mcYield[-1].append(v)\n",
    "    mcYield = np.array(mcYield)\n",
    "\n",
    "    errs = h.integrate('systematic',syst)._sumw2\n",
    "\n",
    "    mcYieldErr = []\n",
    "    for s in errs:\n",
    "        mcYieldErr.append(errs[s]**0.5)\n",
    "\n",
    "    mcYieldErr = np.array(mcYieldErr)\n",
    "    mcYieldErr.shape = (3,6)\n",
    "    mcYieldErr = mcYieldErr.transpose()\n",
    "\n",
    "    misIDEleSF = MisIDSFResults[syst]\n",
    "\n",
    "    mcYield[:,1] *= misIDEleSF\n",
    "    mcYieldErr[:,1] *= misIDEleSF\n",
    "\n",
    "    \n",
    "    fitDataSyst = {\n",
    "        'mcYield':mcYield, \n",
    "        'mcYieldErr':mcYieldErr,\n",
    "        'photonPurity':photonPurityResults[syst][0], \n",
    "        'photonPurityErr':photonPurityResults[syst][1],\n",
    "        'topPurity':topPurityResults[syst][0],\n",
    "        'topPurityErr':topPurityResults[syst][1], \n",
    "        'nData':nData, \n",
    "    }\n",
    "    \n",
    "    output = maximizeLikelihood(fitDataSyst,\n",
    "                            nSteps=100, \n",
    "                            find1sigma=False, \n",
    "                            nStepsErr=100, \n",
    "                            startTTGamma=1,\n",
    "                            startNonprompt=1\n",
    "                           )\n",
    "    bestTTGSF, bestNPSF, bestLk = output\n",
    "    systResults[syst] = bestTTGSF\n",
    "\n",
    "print (systResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood scan plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make plots of likelihood scans for ttgamma scale factor and non prompt scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "ttgVals = np.arange(0,2.,.01)\n",
    "for ttgSF in ttgVals:\n",
    "    _ttg, _np, _lk = maximizeLikelihood(fitData, ttgSF = ttgSF, nSteps=50)\n",
    "    lkVals.append(-2*np.log(_lk/mxLk))\n",
    "\n",
    "lkVals = np.array(lkVals)\n",
    "\n",
    "plt.scatter(ttgVals[lkVals<6],lkVals[lkVals<6],color='blue')\n",
    "plt.scatter(ttgVals[lkVals<4],lkVals[lkVals<4],color='yellow')\n",
    "plt.scatter(ttgVals[lkVals<1],lkVals[lkVals<1],color='green')\n",
    "plt.ylabel(\"2*NLL\")\n",
    "plt.xlabel(\"$t\\overline{t}\\gamma$ SF\")\n",
    "\n",
    "ttgVals2Sig = ttgVals[lkVals<5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "npVals = np.arange(0,2.,.01)\n",
    "for npSF in npVals:\n",
    "    _ttg, _np, _lk = maximizeLikelihood(fitData, nonPromptSF= npSF, nSteps=50)\n",
    "    lkVals.append(-2*np.log(_lk/mxLk))\n",
    "\n",
    "lkVals = np.array(lkVals)\n",
    "\n",
    "plt.scatter(npVals[lkVals<6],lkVals[lkVals<6],color='blue')\n",
    "plt.scatter(npVals[lkVals<4],lkVals[lkVals<4],color='yellow')\n",
    "plt.scatter(npVals[lkVals<1],lkVals[lkVals<1],color='green')\n",
    "plt.ylabel(\"2*NLL\")\n",
    "plt.xlabel(\"Nonprompt SF\")\n",
    "\n",
    "npVals2Sig = npVals[lkVals<5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "for npSF in npVals2Sig:\n",
    "    _lkVals = []\n",
    "    for ttg in ttgVals2Sig:\n",
    "        _ttg, _np, _lk = maximizeLikelihood(fitData, ttgSF= ttg, nonPromptSF= npSF, nSteps=1)\n",
    "        _lkVals.append(-2*np.log(_lk/mxLk))\n",
    "    lkVals.append(_lkVals)\n",
    "lkVals = np.array(lkVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(ttgVals2Sig, npVals2Sig, lkVals, [0,1,4],colors=['green','yellow'])\n",
    "plt.plot(bestTTGSF, bestNPSF,marker='+',color='black',markersize=12,markeredgewidth=3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaenv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
